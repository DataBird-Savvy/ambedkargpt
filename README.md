# AmbedkarGPT â€“ SEMRAG-based RAG System

## ğŸ“Œ Overview
AmbedkarGPT is a Retrieval-Augmented Generation (RAG) system implemented
based on the **SEMRAG research paper**.  
The system answers questions about **Dr. B. R. Ambedkarâ€™s works** by
combining semantic chunking, knowledge graphs, and graph-based retrieval
with a local Large Language Model (LLM).

---

## ğŸ§  System Architecture
The system follows the SEMRAG pipeline:

1. **Semantic Chunking**
   - Sentence embeddings with cosine similarity
   - Buffer merging for contextual continuity
   - Token-aware chunk splitting

2. **Knowledge Graph Construction**
   - Entity extraction using spaCy
   - Relationship extraction via dependency parsing
   - Graph construction using NetworkX
   - Community detection (Louvain / Leiden)

3. **Retrieval Strategies**
   - **Local Graph RAG Search** (Equation 4 â€“ SEMRAG)
   - **Global Graph RAG Search** (Equation 5 â€“ SEMRAG)
   - Similarity thresholding and ranking
   | **Strategy**                            | **Focus Level** | **Retrieval Method**                                                | **Key Steps**                                                                                                                                                                                                                                                                                                              | **Output**                                        |
| --------------------------------------- | --------------- | ------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------- |
| **Local Graph RAG**<br/>(SEMRAG Eq. 4)  | Entity-level    | Retrieves chunks directly linked to entities in the knowledge graph | â€¢ Compute cosine similarity between query and entity embeddings<br/>â€¢ Filter entities with similarity â‰¥ Ï„<sub>e</sub><br/>â€¢ Retrieve chunks linked to filtered entities<br/>â€¢ Compute similarity between query and chunk embeddings<br/>â€¢ Filter chunks with similarity â‰¥ Ï„<sub>d</sub><br/>â€¢ Rank and select top-K chunks | Highly precise, entity-specific evidence          |
| **Global Graph RAG**<br/>(SEMRAG Eq. 5) | Community-level | Retrieves chunks from relevant graph communities                    | â€¢ Compute community embeddings (mean of entity embeddings)<br/>â€¢ Compute similarity between query and community embeddings<br/>â€¢ Select top-K communities<br/>â€¢ Collect chunks from selected communities<br/>â€¢ Rank chunks using combined similarity score                                                                 | Broader, thematic context for multi-hop reasoning |
| **Similarity Thresholding**             | Both            | Filters low-relevance entities and chunks                           | â€¢ Apply Ï„<sub>e</sub> for entity similarity<br/>â€¢ Apply Ï„<sub>d</sub> for chunk similarity                                                                                                                                                                                                                                 | Noise reduction, improved precision               |
| **Top-K Ranking**                       | Both            | Limits context size and prioritizes relevance                       | â€¢ Rank candidates by final score<br/>â€¢ Select top-K results                                                                                                                                                                                                                                                                | Controlled context size, lower latency            |



4. **LLM Integration**
   - Local LLM (Llama3 / Mistral via Ollama)
   - Prompt templates with retrieved entities & summaries
   - Answer generation with citations

---

## ğŸ› ï¸ Tech Stack
- **Python 3.9+**
- sentence-transformers
- spaCy
- networkx
- scikit-learn
- langchain
- Ollama (Llama3 / Mistral)

---

## ğŸ“‚ Project Structure



ambedkargpt/
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ Ambedkar_works.pdf
â”‚ â””â”€â”€ processed/
â”‚ â”œâ”€â”€ chunks.json
â”‚ â””â”€â”€ knowledge_graph.pkl
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ chunking/
â”‚ â”‚ â”œâ”€â”€ semantic_chunker.py # Algorithm 1 (SEMRAG)
â”‚ â”‚ â””â”€â”€ buffer_merger.py
â”‚ â”œâ”€â”€ graph/
â”‚ â”‚ â”œâ”€â”€ entity_extractor.py
â”‚ â”‚ â”œâ”€â”€ graph_builder.py
â”‚ â”‚ â”œâ”€â”€ community_detector.py
â”‚ â”‚ â””â”€â”€ summarizer.py
â”‚ â”œâ”€â”€ retrieval/
â”‚ â”‚ â”œâ”€â”€ local_search.py # Equation 4 (SEMRAG)
â”‚ â”‚ â”œâ”€â”€ global_search.py # Equation 5 (SEMRAG)
â”‚ â”‚ â””â”€â”€ ranker.py
â”‚ â”œâ”€â”€ llm/
â”‚ â”‚ â”œâ”€â”€ llm_client.py
â”‚ â”‚ â”œâ”€â”€ prompt_templates.py
â”‚ â”‚ â””â”€â”€ answer_generator.py
â”‚ â””â”€â”€ pipeline/
â”‚ â””â”€â”€ ambedkargpt.py # Main pipeline
â”œâ”€â”€ tests/
â”‚ â”œâ”€â”€ test_chunking.py
â”‚ â”œâ”€â”€ test_retrieval.py
â”‚ â””â”€â”€ test_integration.py
â”œâ”€â”€ config.yaml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â””â”€â”€ README.md

## ğŸ“š References

- SEMRAG: Semantic Retrieval-Augmented Generation (Research Paper)
- Dr. B. R. Ambedkar â€“ Collected Works

## Output:

![alt text](image.png)